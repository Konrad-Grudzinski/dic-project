{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc562dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType\n",
    "import pyspark.sql.functions as f\n",
    "import os\n",
    "from custom_utils import *\n",
    "import requests\n",
    "import json\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from calendar import monthrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.\\\n",
    "    builder.\\\n",
    "    appName(\"load_weather_data-notebook\").\\\n",
    "    config(\"spark.mongodb.input.uri\",\"mongodb://127.0.0.1:27017/dic.weather\").\\\n",
    "    config(\"spark.mongodb.output.uri\",\"mongodb://127.0.0.1:27017/dic.weather\").\\\n",
    "    config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\").\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_schema = StructType() \\\n",
    "      .add(\"station_uuid\",StringType(),True) \\\n",
    "      .add(\"latitude\",DoubleType(),True) \\\n",
    "      .add(\"longitude\",DoubleType(),True) \\\n",
    "      .add(\"city\",StringType(),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71115fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_data = spark.read.format(\"csv\") \\\n",
    "      .schema(stations_schema) \\\n",
    "      .load(os.path.join(project_base_dir, \"outputs/selected_stations_unique.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e30f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = stations_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b43f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_weather_data(latitude, longitude, start_date, end_date):\n",
    "    url = f\"https://archive-api.open-meteo.com/v1/archive?latitude={latitude}&longitude={longitude}&start_date={start_date}&end_date={end_date}&hourly=temperature_2m,rain,cloudcover\"\n",
    "    response = json.loads(requests.get(url).text)\n",
    "    return response[\"hourly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5bf5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_data_to_df(uuid, weather_data):\n",
    "    df = pd.DataFrame.from_dict(weather_data)\n",
    "    df[\"station_uuid\"] = uuid\n",
    "    df['dateTime'] = pd.to_datetime(df['time'], format=\"%Y-%m-%dT%H:%M\")\n",
    "    df[\"date\"] = df[\"dateTime\"].dt.date\n",
    "    df[\"hour\"] = df[\"dateTime\"].dt.hour\n",
    "    del df[\"time\"]\n",
    "    del df[\"dateTime\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8552c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_strings(year, start_month, end_month):\n",
    "    return f\"{year}-{start_month:02d}-01\", f\"{year}-{end_month:02d}-{monthrange(year, end_month)[1]:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d706d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(pd_dfs):\n",
    "    joined_df = pd.concat(pd_dfs)\n",
    "    return spark.createDataFrame(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_dataframe(stations):\n",
    "    dfs = []\n",
    "    start_date, end_date = create_date_strings(year, min(months), max(months))\n",
    "    for _, row in stations.iterrows():\n",
    "        weather_dict = retrieve_weather_data(row[\"latitude\"], row[\"longitude\"], start_date, end_date)\n",
    "        weather_df = weather_data_to_df(row[\"station_uuid\"], weather_dict)\n",
    "        dfs.append(weather_df)\n",
    "    return create_dataframe(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0044a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_per_station = get_weather_dataframe(stations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df66478",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_per_station.show(10)\n",
    "print(weather_data_per_station.count())\n",
    "print(weather_data_per_station.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_per_station.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
